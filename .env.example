# LMA Docker Configuration
# For all providers visit: https://docs.litellm.ai/docs/providers

# ========== Model Configuration ==========
DEFAULT_MODEL=gemini-2.5-flash

# ========== API Keys ==========
# Add your API keys for the providers you want to use

# # OpenAI
# OPENAI_API_KEY=
# OPENAI_ORGANIZATION=
# OPENAI_BASE_URL=
#
# # Azure OpenAI
# AZURE_API_KEY=
# AZURE_API_BASE=
# AZURE_API_VERSION=
# AZURE_DEPLOYMENT_NAME=
#
# # Anthropic
# ANTHROPIC_API_KEY=
# ANTHROPIC_BASE_URL=
#
# # Google (Vertex AI, Gemini)
# GOOGLE_API_KEY=
# GOOGLE_APPLICATION_CREDENTIALS=
# VERTEXAI_PROJECT=
# VERTEXAI_LOCATION=
# GEMINI_API_KEY=
#
# # AWS Bedrock
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_REGION_NAME=
#
# # Cohere
# COHERE_API_KEY=
# COHERE_API_BASE=
#
# # Mistral AI
# MISTRAL_API_KEY=
# MISTRAL_API_BASE=
#
# # Hugging Face
# HUGGINGFACE_API_KEY=
# HUGGINGFACE_API_BASE=
#
# # Together AI
# TOGETHER_API_KEY=
# TOGETHER_API_BASE=
#
# # OpenRouter
# OPENROUTER_API_KEY=
#
# # Groq
# GROQ_API_KEY=
#
# # Perplexity AI
# PERPLEXITYAI_API_KEY=
#
# # Fireworks AI
# FIREWORKS_API_KEY=
#
# # Databricks
# DATABRICKS_API_KEY=
# DATABRICKS_API_BASE=
#
# # Nvidia NIM
# NVIDIA_API_KEY=
#
# # Replicate
# REPLICATE_API_TOKEN=
#
# # AI21
# AI21_API_KEY=
#
# # Baseten
# BASETEN_API_KEY=
#
# # Cloudflare
# CLOUDFLARE_API_KEY=
# CLOUDFLARE_ACCOUNT_ID=
#
# # Ollama
# OLLAMA_API_BASE=
#
# # Custom LiteLLM Proxy
# LITELLM_PROXY_API_KEY=
# LITELLM_PROXY_API_BASE=
#
# ========== Security Configuration ==========
# Generate a secure session secret for production
SESSION_SECRET_KEY=your-super-secret-session-key-here

# ========== Environment Settings ==========
# NEVER set DEBUG_MODE=true in production!
DEBUG_MODE=false

